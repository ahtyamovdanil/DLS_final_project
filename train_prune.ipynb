{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import imp\n",
    "#import TransformerTrainer\n",
    "import MyTransformer\n",
    "import PruningTrainer\n",
    "imp.reload(PruningTrainer)\n",
    "imp.reload(MyTransformer)\n",
    "from PruningTrainer import BaseDataModule, MyPruningTrainer\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "import random\n",
    "import numpy as np\n",
    "import utils\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:16:8\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "%env CUBLAS_WORKSPACE_CONFIG :16:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "BATCH_SIZE = 64\n",
    "MAX_LEN = 50\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.set_deterministic(True)\n",
    "\n",
    "data_module = BaseDataModule(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device = DEVICE,\n",
    "    data_path=\"./data/eng_rus.txt\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"src_vocab_size\": data_module.src_vocab_len,\n",
    "    \"trg_vocab_size\": data_module.trg_vocab_len,\n",
    "    \"d_model\": 512,\n",
    "    \"n_enc_layers\": 6,\n",
    "    \"n_dec_layers\": 6,\n",
    "    \"n_enc_heads\": 8,\n",
    "    \"n_dec_heads\": 8,\n",
    "    \"enc_dropout\": 0.1,\n",
    "    \"dec_dropout\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyTransformer.Transformer(**model_params)\n",
    "checkpoint = torch.load(\"models/transformer_model.pt\")\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plmodel = MyPruningTrainer(\n",
    "    model, data_module.src_pad_idx, data_module.trg_pad_idx, 1e-4\n",
    ")\n",
    "plmodel.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0     \n",
      "1 | model     | Transformer      | 57.1 M\n",
      "2 | pruner    | Pruner           | 180   \n",
      "-----------------------------------------------\n",
      "57.1 M    Trainable params\n",
      "36        Non-trainable params\n",
      "57.1 M    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7545e635c79b4fbfa96e3cb10e33afcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ed0b5f84d14515a571e39a2c9df97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "plmodel.lr = 1e-4\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger('./logs/')\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='total_val_loss',\n",
    "   min_delta=0.01,\n",
    "   patience=2,\n",
    "   verbose=False,\n",
    "   mode='mean'\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=N_EPOCHS,\n",
    "    gradient_clip_val=CLIP,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    callbacks=[early_stop_callback, lr_monitor], \n",
    "    logger=tb_logger,\n",
    "    log_every_n_steps=20\n",
    ")\n",
    "data_module.setup('fit')\n",
    "trainer.fit(plmodel, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pruner\n",
    "import imp\n",
    "imp.reload(Pruner)\n",
    "from Pruner import Pruner\n",
    "\n",
    "pruner = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plmodel.pruner.enc_attn_weights[0]\n",
    "plmodel.pruner.get_probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[65., 73., 76., 80., 72., 69., 70., 78.],\n        [71., 70., 74., 72., 66., 75., 82., 81.],\n        [82., 78., 73., 75., 77., 74., 69., 72.],\n        [74., 71., 76., 77., 81., 79., 67., 79.],\n        [76., 77., 82., 69., 77., 75., 69., 68.],\n        [78., 83., 73., 77., 73., 80., 82., 70.]], device='cuda:0')"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = plmodel.pruner.get_all_gates()[\"enc_gates\"]\n",
    "for i in range(100):\n",
    "    a += plmodel.pruner.get_all_gates()[\"enc_gates\"]\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " with torch.no_grad():\n",
    "    mask = plmodel.pruner.get_all_gates()[\"enc_gates\"]\n",
    "    d_size = plmodel.pruner.enc_attn_weights[0].shape[0]\n",
    "    for m, w in zip(mask, plmodel.pruner.enc_attn_weights):\n",
    "        w_new = w.view(d_size, 8, -1) * m.view(1, -1, 1)\n",
    "        w.copy_(w_new.view(d_size, d_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(32768, device='cuda:0')"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(plmodel.model.encoder.layers[0].attn.fc_out.weight.view(d_size, 8, -1).permute(1, 0 , -1)[6] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(32768, device='cuda:0')"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(plmodel.model.encoder.layers[0].attn.fc_out.weight == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'enc_gates': 0.8333333333333334, 'dec_gates': 0.7708333333333334}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plmodel.pruner.get_total_sparsity_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}