{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import imp\n",
    "import MyTransformer\n",
    "import PruningTrainer\n",
    "imp.reload(PruningTrainer)\n",
    "imp.reload(MyTransformer)\n",
    "from PruningTrainer import MyPruningTrainer\n",
    "from DataModule import BaseDataModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "import random\n",
    "import numpy as np\n",
    "import utils\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:16:8\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "%env CUBLAS_WORKSPACE_CONFIG :16:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "BATCH_SIZE = 64\n",
    "MAX_LEN = 50\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.set_deterministic(True)\n",
    "\n",
    "data_module = BaseDataModule(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device = DEVICE,\n",
    "    data_path=\"./data/eng_rus.txt\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"src_vocab_size\": data_module.src_vocab_len,\n",
    "    \"trg_vocab_size\": data_module.trg_vocab_len,\n",
    "    \"d_model\": 512,\n",
    "    \"n_enc_layers\": 6,\n",
    "    \"n_dec_layers\": 6,\n",
    "    \"n_enc_heads\": 8,\n",
    "    \"n_dec_heads\": 8,\n",
    "    \"enc_dropout\": 0.1,\n",
    "    \"dec_dropout\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyTransformer.Transformer(**model_params)\n",
    "checkpoint = torch.load(\"models/transformer_model_pruned.pt\")\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plmodel = MyPruningTrainer(\n",
    "    model, data_module.src_pad_idx, data_module.trg_pad_idx, 1e-4\n",
    ")\n",
    "plmodel.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0     \n",
      "1 | model     | Transformer      | 57.1 M\n",
      "2 | pruner    | Pruner           | 57.1 M\n",
      "-----------------------------------------------\n",
      "27.1 M    Trainable params\n",
      "30.0 M    Non-trainable params\n",
      "57.1 M    Total params\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "987b316014eb48c880cef0759a464657"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "910494b294504e3abd3dc4e39bb552a4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7efe7a8a462b494887ab1d25c55716b4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "febf38de9075409e8b6f667caee0b61a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c8128bf405649438b57a830d1e9d1e6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4aa5941945c44eab883d32e37fc7146"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcc62ffcb9904b2684b2d6643092e62a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cbcce321dc1d4637813ee1f903ac3f36"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 6\n",
    "CLIP = 1\n",
    "plmodel.lr = 1e-4\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger('./logs/')\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='total_val_loss',\n",
    "   min_delta=0.01,\n",
    "   patience=2,\n",
    "   verbose=False,\n",
    "   mode='mean'\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=N_EPOCHS,\n",
    "    gradient_clip_val=CLIP,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    callbacks=[lr_monitor], \n",
    "    logger=tb_logger,\n",
    "    log_every_n_steps=20\n",
    ")\n",
    "data_module.setup('fit')\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    trainer.fit(plmodel, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(plmodel.model.state_dict(), 'models/transformer_model_pruned.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.604\n"
     ]
    }
   ],
   "source": [
    "plmodel.pruner.get_total_sparsity_rate()"
   ]
  },
  {
   "source": [
    "### В модели осталось меньше 2/3 от изначального числа голов\n",
    "### Посчитаем теперь bleu на модели с удаленными головами"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "utils.calculate_bleu(\n",
    "    data = data_module.test_iter, \n",
    "    src_field = data_module.src_field, \n",
    "    trg_field = data_module.trg_field,\n",
    "    model = plmodel.model,\n",
    "    device=DEVICE\n",
    ")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=7500.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ff476ffa36d4fbca78e9c7fb0789afe"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.24293770822074123"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.242 bleu у срезанной модели против 0.261 у оригинальной"
   ]
  },
  {
   "source": [
    "## Визуализируем как выключались головы по мере обучения"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "with open(\"./data/probs.txt\", 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        all_data.extend([float(item) for item in line.split()])\n",
    "\n",
    "all_data = np.array(all_data).reshape([-1, 6, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(all_data):\n",
    "    fig,ax = plt.subplots(figsize=(8, 5.5))\n",
    "    fig.suptitle(f\"batch: {i*10}\", fontsize=16)\n",
    "    heatmap = sns.heatmap(data, vmin=0, vmax=1, cmap=\"YlGnBu_r\")\n",
    "    plt.xlabel('head', fontsize=14)\n",
    "    plt.ylabel('layer', fontsize=14)\n",
    "    ax.set_xticklabels(range(1, 9))\n",
    "    ax.set_yticklabels(range(1, 7))\n",
    "    plt.savefig(f\"images/image{i}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PilImage\n",
    "\n",
    "im1 = PilImage.open(\"./images/image0.png\")\n",
    "imgs = (PilImage.open(f\"./images/image{i}.png\") for i in range(377))\n",
    "\n",
    "im1.save(fp=\"./gifs/pruning.gif\", format='GIF', append_images=imgs,\n",
    "         save_all=True, duration=50, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gifsicle -O3 --colors 256 --lossy=30 -o ./temp/test2.gif ./temp/test.gif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./gifs/pruning.gif','rb') as f:\n",
    "    display(Image(data=f.read(), format='png'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (fake_news)",
   "language": "python",
   "name": "pycharm-ddc00e7f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}